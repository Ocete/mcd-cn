{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ac98537",
   "metadata": {},
   "source": [
    "%%html\n",
    "<style>\n",
    "    .exercise {\n",
    "        background-color: #AFEEEE;\n",
    "        font-style: normal;\n",
    "        text-align: justify;\n",
    "        margin-left: 0px;\n",
    "        margin-right: 10px;\n",
    "        margin-top: 10px;\n",
    "        margin-bottom: 0px;\n",
    "        display: block;\n",
    "    }\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01c6a0a9",
   "metadata": {},
   "source": [
    "<center style=\"font-size:20px;padding-bottom:10px;\">Máster en Ciencia de Datos -  Universidad Autónoma de Madrid</center>\n",
    "\n",
    "<center style=\"font-size:20px;padding-bottom:10px;\">José Antonio Álvarez Ocete</center>\n",
    "\n",
    "<center style=\"font-size:20px;\">Francisco Javier Sáez Maldonado</center>\n",
    "\n",
    "# Introducción\n",
    "\n",
    "\n",
    "En un *enfoque bayesiano* de la estadística, un parámetro $\\theta$ se\n",
    "considera una variable aleatoria con una determinada distribución de\n",
    "probabilidad. El teorema de Bayes relaciona la información inicial que\n",
    "se tiene del parámetro $\\theta$ antes de realizar un experimento y la\n",
    "información que se dispone después de realizar el experimento.\n",
    "\n",
    "-   La información inicial que se tiene sobre $\\theta$ se representa\n",
    "    mediante su *distribución a priori* $\\pi(\\theta)$\n",
    "\n",
    "-   La información que se tiene de $\\theta$ después de realizar uno\n",
    "    (o varios) experimento/s, $x$, se codifica mediante su\n",
    "    *distribución a posteriori* $\\pi(\\theta | x)$.\n",
    "\n",
    "-   El teorema de Bayes nos permite obtener la densidad de probabilidad\n",
    "    $\\pi(\\theta | x)$ en función del resultado del experimento y la\n",
    "    densidad de probabilidad a priori $\\pi(\\theta)$\n",
    "\n",
    "$$\n",
    "    \\pi(\\theta | x) = \\frac{ \\pi(x | \\theta) } { \\int_{-\\infty}^{\\infty} \\pi(x | \\theta) \\pi(\\theta) \\; d\\theta} \\; \\pi(\\theta)\n",
    "$$\n",
    "\n",
    "-   La cantidad $\\pi(x | \\theta)$ del numerador se denomina\n",
    "    *verosimilitud* (*likelihood*). Es una **función** y representa la\n",
    "    probabilidad de observar el resultado del experimento $x$\n",
    "    (muestra) en función del valor del parámetro $\\theta$\n",
    "\n",
    "    $$ \\pi(x | \\theta) = \\prod_i f(x_i | \\theta) $$\n",
    "\n",
    "    siendo $x_i$ con $i=1, \\ldots, n$ los resultados del\n",
    "    experimento (valores muestrales) y $f(x_i | \\theta)$ sus\n",
    "    probabilidades para un determinado valor de $\\theta$.\n",
    "\n",
    "-   El denominador $\\int_{-\\infty}^{\\infty} \\pi(x | \\theta)\n",
    "    \\pi(\\theta) \\; d\\theta$, una vez realizada la integración,\n",
    "    **no** depende del parámetro $\\theta$. Es una constante de\n",
    "    normalización.\n",
    "\n",
    "-   Para realizar previsiones se utilizan *distribuciones predictivas*\n",
    "    (valor esperado de una determinada función)\n",
    "\n",
    "$$\n",
    "    E[ g(y|x) ] = \\int g(y| \\theta) \\; \\pi(\\theta | x)\\; d\\theta\n",
    "$$\n",
    "\n",
    "Por ejemplo, es habitual usar como *predictor* del valor de la v.a\n",
    "    $\\theta$ su valor esperado: $$ \\widehat{\\theta} = \\int\n",
    "    \\theta \\; \\pi(\\theta | x) \\; d\\theta $$\n",
    "\n",
    "-   Cuando las distribuciones a priori y a posteriori son del mismo tipo\n",
    "    se dice que son \"conjugadas a priori\". A menudo esto implica grandes\n",
    "    beneficios desde el punto de vista computacional.\n",
    "\n",
    "\n",
    "-   La descripción formal de la inferencia bayesiana es sencilla, sin\n",
    "    embargo su implementación **habitualmente no es fácil** y requiere\n",
    "    Métodos de Monte Carlo.\n",
    "\n",
    "<p class=\"exercise\">\n",
    "\n",
    "    <h1>Ejercicio 1</h1> <a href=\"#Ejercicio-1\" class=\"anchor-link\">¶</a>\n",
    "\n",
    "    Estimar la probabilidad de que un paciente ingresado\n",
    "    en planta acabe en la UCI. Para realizar este problema mediante\n",
    "    inferencia Bayesiana debemos tener en cuenta: \n",
    "    * La probabilidad de que un paciente ingresado en planta acabe en la UCI será nuestro parámetro\n",
    "    $\\theta$. Como hemos visto, en el enfoque bayesiano debemos\n",
    "    considerar que $\\theta$ es una variable aleatoria. \n",
    "    * Debemos conocer\n",
    "    la distribución de la v.a $\\theta$ **antes** de realizar el\n",
    "    experimento, es decir su *densidad de probabilidad a priori*\n",
    "    $\\pi(\\theta)$. Supongamos, por ejemplo, que $\\pi(\\theta) =\n",
    "    B(\\theta | \\alpha = 5, \\beta = 10)$. \n",
    "    * Debemos incorporar el\n",
    "    resultado del experimento. Considerad el siguiente experimento: se\n",
    "    contabiliza cuantos de los pacientes que hay en planta ($n$) deben\n",
    "    ingresar en la UCI ($k$). Se observa que de los $n=20$ pacientes en\n",
    "    planta $k=1$ ingresan en la UCI. \n",
    "        * Debemos calcular la función de\n",
    "    verosimilitud $\\pi(x | \\theta)$ del resultado del experimento. La\n",
    "    función de verosimilitud será proporcional a la probabilidad de observar\n",
    "    el resultado del experimento en función del valor de $\\theta$): $$\n",
    "    \\pi(x | \\theta) \\propto \\theta^k (1-\\theta)^{n-k} $$ donde, en\n",
    "    este caso, habría que substituir $n=20$ y $k=1$. Notad como en la\n",
    "    ecuación anterior $\\pi(x|\\theta)$ **no** está normalizada. \n",
    "    * Debemos elegir un *predictor* adecuado a nuestro problema. Como\n",
    "    predictor de $\\theta$ *la probabilidad de que un paciente de la\n",
    "    planta acabe en la UCI* utilizaremos su valor esperado\n",
    "    $E[\\theta]$. Nos preguntarnos entonces:\n",
    "\n",
    "        1. ¿Cuál es el valor de $E[\\theta]$ **antes** de realizar el experimento? \n",
    "        2. ¿Cuál es el valor de $E[\\theta]$ **después** de observar el resultado del experimento? **Ayuda** * La pregunta (1) es fácil. Al ser la distribución a priori $\\pi(\\theta)$ la distribución $Beta$, su valor esperado será\n",
    "        $$ \\mu_{\\text{prior}} = E[\\theta]_{\\text{prior}} = \\int_{-\\infty}^{\\infty} \\theta \\; B(\\theta | \\alpha, \\beta) \\; d\\theta = \\frac{\\alpha}{\\alpha + \\beta} $$\n",
    "        \n",
    "        * Para la pregunta (2) se debe calcular: $$ \\mu_{\\text{posterior}}= E[\\theta]_{\\text{posterior}} = \\int_{-\\infty}^{\\infty} \\theta \\; \\pi(\\theta | x) \\; d\\theta $$\n",
    "        Para ello se necesita conocer la distribución a posteriori $\\pi(\\theta | x)$. Utilizando el teorema de Bayes, tras re-ordenar términos se obtiene: \n",
    "\n",
    "\n",
    "    \\begin{align*} \n",
    "        E[\\theta]_{\\text{posterior}} &=\n",
    "        \\int_{-\\infty}^{\\infty} \\theta \\; \\pi(\\theta | x) \\; d \\theta \n",
    "        \\ &= \\int_{-\\infty}^{\\infty} \\theta \\; \\frac{ \\pi(x |\n",
    "        \\theta) \\; \\pi(\\theta) } { \\int_{-\\infty}^{\\infty} \\pi(x |\n",
    "        \\theta) \\pi(\\theta) \\; d \\theta} \\; d \\theta = \\frac{\n",
    "        \\int_{-\\infty}^{\\infty} \\theta \\; \\pi(x | \\theta) \\;\n",
    "        \\pi(\\theta) \\; d \\theta } { \\int_{-\\infty}^{\\infty} \\pi(x |\n",
    "        \\theta) \\; \\pi(\\theta) \\; d \\theta} \n",
    "        \\ &= \\frac{\\int_{-\\infty}^{\\infty} \\theta \\; \\theta^k\n",
    "        (1-\\theta)^{n-k} \\; \\; \\pi(\\theta) \\; d \\theta } {\n",
    "        \\int_{-\\infty}^{\\infty} \\pi(x | \\theta) \\; \\pi(\\theta) \\;\n",
    "        d \\theta} = \\frac{ \\int_{0}^{1} \\; \\theta^{k+1} (1-\\theta)^{n-k}\n",
    "        \\; \\; B(\\theta | \\alpha=5, \\beta=10) \\; d \\theta } {\n",
    "        \\int_{0}^{1} \\theta^{k} (1-\\theta)^{n-k} \\; B(\\theta | \\alpha=5,\n",
    "        \\beta=10) \\; d \\theta}\n",
    "    \\end{align*} \n",
    "\n",
    "    donde se han sustituído los\n",
    "    valores de $\\pi(\\theta)$ y de la verosimilitud $\\pi(x | \\theta)$\n",
    "    . Sino supiésemos resolver analíticamente las integrales anteriores (en\n",
    "    este caso sí hay solución analítica aunque no es fácil) podemos\n",
    "    **estimar** el numerador y el denominador mediante integración de\n",
    "    Monte Carlo. \n",
    "</p>\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b581d76740609bb5e5fe8b6dde4f14ada2f356bbcbf8c5a669ffe89e4be307c6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
